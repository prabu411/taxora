# Taxora - IBM Granite Configuration
# Copy this file to .env and configure your preferred setup

# =============================================================================
# GRANITE AI CONFIGURATION (Choose one backend)
# =============================================================================

# Option 1: Local Model (Recommended - Free, Private)
GRANITE_USE_LOCAL=true
GRANITE_USE_API=false
GRANITE_USE_OLLAMA=false

# Model Configuration
GRANITE_MODEL_NAME=ibm-granite/granite-7b-instruct
GRANITE_DEVICE=cpu
GRANITE_MAX_LENGTH=1024
GRANITE_TEMPERATURE=0.7

# =============================================================================
# HUGGING FACE CONFIGURATION
# =============================================================================

# Get your free token from: https://huggingface.co/settings/tokens
# Required for API mode, optional for local mode (faster downloads)
HUGGINGFACE_TOKEN=your_hf_token_here

# =============================================================================
# OLLAMA CONFIGURATION (Alternative local setup)
# =============================================================================

OLLAMA_BASE_URL=http://localhost:11434

# =============================================================================
# LEGACY IBM WATSON CONFIGURATION (No longer needed)
# =============================================================================

# These are kept for reference but not required for Granite
# WATSONX_APIKEY=YOUR_IBM_CLOUD_API_KEY
# WATSONX_URL=https://us-south.ml.cloud.ibm.com
# WATSONX_PROJECT_ID=YOUR_PROJECT_ID
# WATSONX_MODEL_ID=ibm/granite-3-3-8b-instruct
# WATSONX_API_VERSION=2024-10-10
# NLU_APIKEY=YOUR_WATSON_NLU_API_KEY
# NLU_URL=https://api.us-south.natural-language-understanding.watson.cloud.ibm.com
